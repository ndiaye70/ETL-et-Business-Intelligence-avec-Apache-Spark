# ğŸ› ï¸ Projet ETL et Business Intelligence avec Apache Spark
RealisÃ© par PAPE ABDOULAYE NDIAYE ET MATY SECK

> **AnnÃ©e acadÃ©mique :** 2024â€“2025  
> **UniversitÃ© :** UniversitÃ© Gaston Berger (UGB), Institut Polytechnique de Saint Louis (IPSL)  
> **Enseignant :** Dr. Djibril MBOUP  
> **Classe :** GeIT 3

## ğŸ“Œ Objectif du Projet

DÃ©velopper une solution complÃ¨te **ETL (Extract - Transform - Load)** et **Business Intelligence** Ã  partir de la base de donnÃ©es **AdventureWorks** (SQL Server), en exploitant :

- Apache Spark pour le traitement de donnÃ©es
- PostgreSQL comme entrepÃ´t de donnÃ©es
- Power BI pour la visualisation

## âœ… PrÃ©requis techniques

- [Apache Spark 3.5.0](https://spark.apache.org/)
- [Java JDK 8+](https://www.oracle.com/java/technologies/javase-downloads.html)
- [PostgreSQL 14+](https://www.postgresql.org/download/)
- [Power BI Desktop](https://powerbi.microsoft.com/)
- AccÃ¨s Ã  un conteneur MSSQL avec AdventureWorks (exÃ©cutÃ© via Docker dans **une VM Kali sur VirtualBox**)

## âš™ï¸ Ã‰tapes de dÃ©ploiement

### 1. Connexion Ã  la base MSSQL (hÃ©bergÃ©e dans la VM Kali)

Assurez-vous que votre VM expose le port 1433 (MSSQL) sur lâ€™hÃ´te.


### 2. ExÃ©cution du job Spark ETL a l'aide de la commande "sbt clean assembly"

#### a. Un fichier JAR Spark prÃ©compilÃ© sera generÃ© dans le repertoire du code

-
#### b. Lancer l'ETL a l'aide du fichier jar

```bash
spark-submit \
  --class Main \
  --master local[*] \
  --jars "mssql-jdbc-12.10.0.jre11.jar,postgresql-42.7.6.jar" \
  ficher-jar.jar
```

#### c. ParamÃ¨tres de connexion

- MSSQL : `jdbc:sqlserver://192.168.X.X:1433`
- PostgreSQL : `jdbc:postgresql://localhost:5432/AdventureWorks_DW`

Les identifiants sont Ã  modifier dans le code source (`Main.scala`) si besoin.

---

## ğŸ§  ModÃ¨le de donnÃ©es (PostgreSQL - SchÃ©ma en Ã©toile)

- **Tables de dimensions** : `dim_customer`, `dim_product`, `dim_geography`, `dim_date`
- **Table de faits** : `fact_sales`

---

## ğŸ“Š Visualisation avec Power BI

### 1. Connexion

- Source : PostgreSQL
- Serveur : `localhost`
- Base de donnÃ©es : `AdventureWorks_DW`

### 2. Tables Ã  importer

```text
dim_customer
dim_product
dim_geography
dim_date
fact_sales
```

### 3. Relations Ã  Ã©tablir

| ClÃ©           | Vers dimension           |
|---------------|--------------------------|
| CustomerKey   | dim_customer             |
| ProductKey    | dim_product              |
| GeographyKey  | dim_geography            |
| DateKey       | dim_date                 |

---

## ğŸ“ˆ Tableaux de bord disponibles (les tableaux de bords ont etait realisÃ© sur un seul fichier avec des pages differentes)

### ğŸ”¹ Ventes

- Chiffre d'affaires total
- Ã‰volution par pÃ©riode (mois, trimestre, annÃ©e)
- RÃ©partition par catÃ©gorie



### ğŸ”¹ ClientÃ¨le

- RÃ©partition clients par types 
-Par geographie
-Par fidelitÃ© en se basant sur les differentes periodes

l'analyse geographique a etait integrÃ© aussi bien dans le dashboard Ventes que dans clientÃ¨le

### ğŸ”¹ Performance

- Taux de croissance,  
- Comparaison des ventes par pÃ©riode.

-
---

## ğŸ“ Structure du dÃ©pÃ´t

```
AdventureWorks-ETL-BI/
â”œâ”€â”€ Scala code
â”‚   â”œâ”€â”€ etl-AdventureWorks
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ etl-master.zip
â”œâ”€â”€ powerbi/
â”‚   â”œâ”€â”€ DataIng Project.pbix
â””â”€â”€ README.md
â””â”€â”€ modÃ¨le


---
